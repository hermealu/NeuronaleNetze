% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/NN1.R
\name{NN}
\alias{NN}
\title{S6 class that can generate Neural Networks}
\description{
S6 class that can generate Neural Networks

S6 class that can generate Neural Networks
}
\details{
In this class Neural Networks can be generated and optimized via different
Gradient Descends Methods

\describe{ \item{L}{number of hidden layers}

\item{B}{width of each layer}

\item{W}{weight matrices}

\item{d}{width vector}

\item{f}{activation function}

\item{del_f}{derivative of the activation function} }
}
\section{Public fields}{
\if{html}{\out{<div class="r6-fields">}}
\describe{
\item{\code{L}}{A scalar, which refers to the number of hidden layers}

\item{\code{B}}{An atomic vector, which contains the width of the input, the hidden layers and the output}

\item{\code{W}}{A list with length L+1, which contains matrix-inputs of the weight matrices of the neural network}

\item{\code{d}}{A list with length L+1, which contains atomic vectors. They represent the affine vectors of the neural network}

\item{\code{f}}{A function, which represents the activation function}

\item{\code{del_f}}{A function, which represents the derivative of the activation function}
}
\if{html}{\out{</div>}}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-new}{\code{NN$new()}}
\item \href{#method-ffprop}{\code{NN$ffprop()}}
\item \href{#method-ffprop_clas}{\code{NN$ffprop_clas()}}
\item \href{#method-eval_till_layer}{\code{NN$eval_till_layer()}}
\item \href{#method-eval_till_layer_z}{\code{NN$eval_till_layer_z()}}
\item \href{#method-GD}{\code{NN$GD()}}
\item \href{#method-BP_reg}{\code{NN$BP_reg()}}
\item \href{#method-SGD}{\code{NN$SGD()}}
\item \href{#method-SGD_clas}{\code{NN$SGD_clas()}}
\item \href{#method-BP_clas}{\code{NN$BP_clas()}}
\item \href{#method-clone}{\code{NN$clone()}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-new"></a>}}
\if{latex}{\out{\hypertarget{method-new}{}}}
\subsection{Method \code{new()}}{
Initializing a neural network
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{NN$new(
  L = 1,
  B = c(1, 1, 1),
  W = c(1, 1, 1),
  d = c(1, 1, 0),
  min_gewicht = -2,
  max_gewicht = 2,
  func = sigmoid,
  del_func = del_sigmoid
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{L}}{A scalar, which refers to the number of hidden layers}

\item{\code{B}}{An atomic vector, which contains the width of the input, the hidden layers and the output}

\item{\code{W}}{A list with length L+1, which contains matrix-inputs of the weight matrices of the neural network}

\item{\code{d}}{A list with length L+1, which contains atomic vectors. They represent the affine vectors of the neural network}

\item{\code{min_gewicht}}{A scalar, which sets the minimal number that can appear in a weight matrix}

\item{\code{max_gewicht}}{A scalar, which sets the maximal number that can appear in a weight matrix}

\item{\code{func}}{A function, which represents the activation function}

\item{\code{del_func}}{A function, which represents the derivative of the activation function}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
A R6 object, which contains the parameters of a neural network and methods for its optimization
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-ffprop"></a>}}
\if{latex}{\out{\hypertarget{method-ffprop}{}}}
\subsection{Method \code{ffprop()}}{
Calculate feedforward propagation for regression of a neural network
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{NN$ffprop(x = 1)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{x}}{A atomic vector or an array, which represents the input of the network}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-ffprop_clas"></a>}}
\if{latex}{\out{\hypertarget{method-ffprop_clas}{}}}
\subsection{Method \code{ffprop_clas()}}{
Calculating feed forward propagation for classification with softmax
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{NN$ffprop_clas(x = matrix(1))}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{x}}{An array, which represents the input of the network}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-eval_till_layer"></a>}}
\if{latex}{\out{\hypertarget{method-eval_till_layer}{}}}
\subsection{Method \code{eval_till_layer()}}{
Calculating feedforward propagation up to a certain layer Layer
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{NN$eval_till_layer(x = 1, Layer = 1)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{x}}{A vector or array}

\item{\code{Layer}}{A scalar smaller than or equal as L+1 and bigger than 0.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-eval_till_layer_z"></a>}}
\if{latex}{\out{\hypertarget{method-eval_till_layer_z}{}}}
\subsection{Method \code{eval_till_layer_z()}}{
Calculating feedforward propagation up to a certain layer without activation function in the last step
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{NN$eval_till_layer_z(x = 1, Layer = 1)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{x}}{A vector or array}

\item{\code{Layer}}{A scalar smaller than or equal as L+1 and bigger than 0.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-GD"></a>}}
\if{latex}{\out{\hypertarget{method-GD}{}}}
\subsection{Method \code{GD()}}{
Method, which calculates a random descent for a neural network
Calculating gradient descent
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{NN$GD(x, y, iteration = 10, delta = 0.02)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{x}}{A vector or array with rows representing the input of the training
data and columns representing the number of different training data}

\item{\code{y}}{A vector or array with rows representing the output of the training
data and columns representing the number of different training data}

\item{\code{iteration}}{A scalar that represents the times the full data is applied in the algorithm}

\item{\code{delta}}{A scalar between 0 and 1 that determines how much the weights change}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-BP_reg"></a>}}
\if{latex}{\out{\hypertarget{method-BP_reg}{}}}
\subsection{Method \code{BP_reg()}}{
A Method, which calculates the Gradient Decent for regression for a neural network
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{NN$BP_reg(x, y, gam = 1e-04)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{x}}{A vector or array with rows representing the input of the training
data and columns representing the number of different training data}

\item{\code{y}}{A vector or array with rows representing the onehotencoded output of the training
data and columns representing the number of different training data}

\item{\code{gam}}{A scalar between zero and 1 that determines how much the weights change}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-SGD"></a>}}
\if{latex}{\out{\hypertarget{method-SGD}{}}}
\subsection{Method \code{SGD()}}{
Calculating stochastic gradient descent
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{NN$SGD(x, y, n, delta = 0.01, iteration = 10)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{x}}{A vector or array with rows representing the input of the training
data and columns representing the number of different training data}

\item{\code{y}}{A vector or array with rows representing the output of the training
data and columns representing the number of different training data}

\item{\code{n}}{A scalar that determines the number of batches}

\item{\code{delta}}{A scalar between 0 and 1 that determines how much the weights change}

\item{\code{iteration}}{A scalar that represents the times the full data is applied in the algorithm}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-SGD_clas"></a>}}
\if{latex}{\out{\hypertarget{method-SGD_clas}{}}}
\subsection{Method \code{SGD_clas()}}{
Calculating stochastic gradient descent for classification
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{NN$SGD_clas(x, y, n, delta = 0.01, iteration = 10)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{x}}{A vector or array with rows representing the input of the training
data and columns representing the number of different training data}

\item{\code{y}}{A vector or array with rows representing the onehotencoded output of the training
data and columns representing the number of different training data}

\item{\code{n}}{A scalar that determines the number of batches}

\item{\code{delta}}{A scalar between 0 and 1 that determines how much the weights change}

\item{\code{iteration}}{A scalar that represents the times the full data is applied in the algorithm}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-BP_clas"></a>}}
\if{latex}{\out{\hypertarget{method-BP_clas}{}}}
\subsection{Method \code{BP_clas()}}{
Calculating gradient descent for classification
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{NN$BP_clas(x, y, gam = 1e-04)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{x}}{A vector or array with rows representing the input of the training
data and columns representing the number of different training data}

\item{\code{y}}{A vector or array with rows representing the onehotencoded output of the training
data and columns representing the number of different training data}

\item{\code{gam}}{A scalar between 0 and 1 that determines how much the weights change}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-clone"></a>}}
\if{latex}{\out{\hypertarget{method-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{NN$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
