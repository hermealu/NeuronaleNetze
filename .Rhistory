print(R1)
print(R2)
if (j %% 10){
print(j/10)
}
}
}
)
)
N1 <- NN$new(4,c(1,50,50,50,50,1))
x <- seq(-2*pi,2*pi,.01)
y_ <- sin(x) + runif(length(seq(-2*pi,2*pi,.01)),min=-0.3,max=0.3)
plot(1,1,xlim=c(-2*pi,2*pi),ylim=c(-2,2))
lines(x,y_,type="l",col="red")
y <- N1$calculate(x)
lines(x,y,col="blue")
N1$GD3(x,y_,3000,0.05)
y <- N1$calculate(x)
lines(x,y,col="yellow")
N1$GD3(x,y_,3000,0.02)
y <- N1$calculate(x)
lines(x,y,col="orange")
N1$GD3(x,y_,3000,0.01)
y <- N1$calculate(x)
lines(x,y,col="Black")
N1$GD3(x,y_,3000,0.005)
y <- N1$calculate(x)
lines(x,y,col="Black")
NN <- R6Class("NN", list(
L = 1, #Anzahl der Layer
B = c(1), #Breite der einzelnen Layer
W = c(1,1), #Liste soll Länge der dim haben und Einträge sind Matrizen W
d = c(1), #List der Affinen Vektoren
J = 0,
theta = c(1,1),
f = tanh,
initialize = function(L = 1, B = c(1,1,1), W = c(1,1,1),d=c(1,1,0), min_gewicht=-2, max_gewicht = 2 ) {
stopifnot(length(B) == L+2)
self$W <- vector(mode="list",length=L+1)
self$L <- L
self$B <- B
#Erstellen der Matrizen W
for (i in (0:L)){
self$W[i+1] <- list(matrix(runif(B[i+1]*B[i+2],min=min_gewicht,max=max_gewicht),nrow=B[i+1],ncol=B[i+2]))
}
names(self$W) <- LETTERS[1:(L+1)]
#Erstellen der affinen Vektoren d
for (i in (0:(L-1))){
self$d[i+1] <- list(matrix(runif(B[i+2],min=min_gewicht,max=max_gewicht),nrow=1,ncol=B[i+2]))
}
self$d[L+1] <- 0
names(self$d) <- LETTERS[1:(L+1)]
#Erstellen des J -> braucht man hier aber wahrscheinlich nicht sondern erst in der Berechnung
for (i in (0:L)){
self$J <- self$J + norm(self$W[[i+1]],"F")
}
#Erstellen der theta
},
#calculate führt die funktion des NN aus
calculate = function(x=1){
for (j in (1:length(x))){
h <- x[j]
if (self$L >= 1){
for (i in LETTERS[1:(self$L)]){
h <- self$f(self$d[[i]] + h %*% self$W[[i]]) #letzter Schritt ist ohne Aktivierungsfunktion
}
}
h <- self$d[[LETTERS[(self$L+1)]]] + h %*% self$W[[LETTERS[(self$L+1)]]]
x[j] <- h
}
return(x)
},
eval_till_layer = function(x=1,Layer=1){
if (Layer == self$L +1){
x <- self$calculate(x)
}
if (self$L >= 1){
for (i in LETTERS[1:(Layer)]){
x <- self$f(self$d[[i]] + x %*% self$W[[i]]) #letzter Schritt ist ohne Aktivierungsfunktion
}
}
return(x)
},
#Durchführen eines Gradientdescends
GD = function(x,y,lambda=1,stepsize=1e-4,iterations=100){
n <- length(x)
R1 <- 1/n * sum((y-self$calculate(x))^2)
for (i in 1:iterations){
self$W[["A"]] <- self$W[["A"]] + 1e-3 * x[i] * (y[i]-self$calculate(x[i]))
}
R2 <- 1/n * sum((y-self$calculate(x))^2)
},
GD2 = function(x,y,lambda=1,stepsize=1e-4,iterations=100){
n <- length(x)
for (i in 1:n){
self$W[[LETTERS[self$L+1]]] <- self$W[[LETTERS[self$L+1]]] + t(0.1*self$eval_till_layer(x[i],self$L)*(y[i]-self$calculate(x[i])))
self$W[[LETTERS[self$L]]] <- self$W[[LETTERS[self$L]]] + 0.1*t(self$W[[LETTERS[self$L+1]]])*self$eval_till_layer(x[i],self$L)*(y[i]-self$calculate(x[i]))
}
},
GD3 = function(x,y,iteration=10,delta=0.02){
for (j in 1:iteration){
W_tmp <- vector(mode="list",length=self$L+1)
names(W_tmp) <- LETTERS[1:(self$L+1)]
d_tmp <- vector(mode="list",length=self$L+1)
names(d_tmp) <- LETTERS[1:(self$L+1)]
R1 <- sum((y-self$calculate(x))^2)
for (k in 1:(self$L +1)){
W_tmp[[LETTERS[k]]] <- self$W[[LETTERS[k]]]
for (l in 1:length(self$W[[LETTERS[k]]])){
self$W[[LETTERS[k]]][l] <- self$W[[LETTERS[k]]][l] + runif(1,min=-delta,max=delta)
}
d_tmp[[LETTERS[k]]] <- self$d[[LETTERS[k]]]
for (l in 1:length(self$d[[LETTERS[k]]])){
self$d[[LETTERS[k]]][l] <- self$d[[LETTERS[k]]][l] + runif(1,min=-delta,max=delta)
}
}
R2 <- sum((y-self$calculate(x))^2)
if (R1 < R2){
self$W <- W_tmp
self$d <- d_tmp
}
print(R1)
print(R2)
if (j %% 10){
print(j/10)
}
}
}
)
)
N1 <- NN$new(4,c(1,50,50,50,50,1))
x <- seq(-2*pi,2*pi,.01)
y_ <- sin(x) + runif(length(seq(-2*pi,2*pi,.01)),min=-0.3,max=0.3)
plot(1,1,xlim=c(-2*pi,2*pi),ylim=c(-2,2))
lines(x,y_,type="l",col="red")
y <- N1$calculate(x)
lines(x,y,col="blue")
N1$GD3(x,y_,3000,0.05)
y <- N1$calculate(x)
lines(x,y,col="Black")
N1$GD3(x,y_,3000,0.05)
y <- N1$calculate(x)
lines(x,y,col="yellow")
y <- N1$calculate(x)
N1$GD3(x,y_,3000,0.001)
y <- N1$calculate(x)
lines(x,y,col="green")
N1$GD3(x,y_,3000,0.005)
y <- N1$calculate(x)
lines(x,y,col="purple")
NN <- R6Class("NN", list(
L = 1, #Anzahl der Layer
B = c(1), #Breite der einzelnen Layer
W = c(1,1), #Liste soll Länge der dim haben und Einträge sind Matrizen W
d = c(1), #List der Affinen Vektoren
J = 0,
theta = c(1,1),
f = id,
initialize = function(L = 1, B = c(1,1,1), W = c(1,1,1),d=c(1,1,0), min_gewicht=-2, max_gewicht = 2 ) {
stopifnot(length(B) == L+2)
self$W <- vector(mode="list",length=L+1)
self$L <- L
self$B <- B
#Erstellen der Matrizen W
for (i in (0:L)){
self$W[i+1] <- list(matrix(runif(B[i+1]*B[i+2],min=min_gewicht,max=max_gewicht),nrow=B[i+1],ncol=B[i+2]))
}
names(self$W) <- LETTERS[1:(L+1)]
#Erstellen der affinen Vektoren d
for (i in (0:(L-1))){
self$d[i+1] <- list(matrix(runif(B[i+2],min=min_gewicht,max=max_gewicht),nrow=1,ncol=B[i+2]))
}
self$d[L+1] <- 0
names(self$d) <- LETTERS[1:(L+1)]
#Erstellen des J -> braucht man hier aber wahrscheinlich nicht sondern erst in der Berechnung
for (i in (0:L)){
self$J <- self$J + norm(self$W[[i+1]],"F")
}
#Erstellen der theta
},
#calculate führt die funktion des NN aus
calculate = function(x=1){
for (j in (1:length(x))){
h <- x[j]
if (self$L >= 1){
for (i in LETTERS[1:(self$L)]){
h <- self$f(self$d[[i]] + h %*% self$W[[i]]) #letzter Schritt ist ohne Aktivierungsfunktion
}
}
h <- self$d[[LETTERS[(self$L+1)]]] + h %*% self$W[[LETTERS[(self$L+1)]]]
x[j] <- h
}
return(x)
},
eval_till_layer = function(x=1,Layer=1){
if (Layer == self$L +1){
x <- self$calculate(x)
}
if (self$L >= 1){
for (i in LETTERS[1:(Layer)]){
x <- self$f(self$d[[i]] + x %*% self$W[[i]]) #letzter Schritt ist ohne Aktivierungsfunktion
}
}
return(x)
},
#Durchführen eines Gradientdescends
GD = function(x,y,lambda=1,stepsize=1e-4,iterations=100){
n <- length(x)
R1 <- 1/n * sum((y-self$calculate(x))^2)
for (i in 1:iterations){
self$W[["A"]] <- self$W[["A"]] + 1e-3 * x[i] * (y[i]-self$calculate(x[i]))
}
R2 <- 1/n * sum((y-self$calculate(x))^2)
},
GD2 = function(x,y,lambda=1,stepsize=1e-4,iterations=100){
n <- length(x)
for (i in 1:n){
self$W[[LETTERS[self$L+1]]] <- self$W[[LETTERS[self$L+1]]] + t(0.1*self$eval_till_layer(x[i],self$L)*(y[i]-self$calculate(x[i])))
self$W[[LETTERS[self$L]]] <- self$W[[LETTERS[self$L]]] + 0.1*t(self$W[[LETTERS[self$L+1]]])*self$eval_till_layer(x[i],self$L)*(y[i]-self$calculate(x[i]))
}
},
GD3 = function(x,y,iteration=10,delta=0.02){
for (j in 1:iteration){
W_tmp <- vector(mode="list",length=self$L+1)
names(W_tmp) <- LETTERS[1:(self$L+1)]
d_tmp <- vector(mode="list",length=self$L+1)
names(d_tmp) <- LETTERS[1:(self$L+1)]
R1 <- sum((y-self$calculate(x))^2)
for (k in 1:(self$L +1)){
W_tmp[[LETTERS[k]]] <- self$W[[LETTERS[k]]]
for (l in 1:length(self$W[[LETTERS[k]]])){
self$W[[LETTERS[k]]][l] <- self$W[[LETTERS[k]]][l] + runif(1,min=-delta,max=delta)
}
d_tmp[[LETTERS[k]]] <- self$d[[LETTERS[k]]]
for (l in 1:length(self$d[[LETTERS[k]]])){
self$d[[LETTERS[k]]][l] <- self$d[[LETTERS[k]]][l] + runif(1,min=-delta,max=delta)
}
}
R2 <- sum((y-self$calculate(x))^2)
if (R1 < R2){
self$W <- W_tmp
self$d <- d_tmp
}
print(R1)
print(R2)
if (j %% 10){
print(j/10)
}
}
}
)
)
N1 <- NN$new(4,c(1,50,50,50,50,1))
x <- seq(-2*pi,2*pi,.01)
y_ <- sin(x) + runif(length(seq(-2*pi,2*pi,.01)),min=-0.3,max=0.3)
plot(1,1,xlim=c(-2*pi,2*pi),ylim=c(-2,2))
lines(x,y_,type="l",col="red")
y <- N1$calculate(x)
lines(x,y,col="blue")
N1$GD3(x,y_,3000,0.005)
N1$GD3(x,y_,3000,0.05)
N1$GD3(x,y_,3000,0.005)
y <- N1$calculate(x)
lines(x,y,col="purple")
N1$GD3(x,y_,3000,0.0005)
y <- N1$calculate(x)
lines(x,y,col="black")
N1$calculate(c(1,1),1)
N1$calculate(c(1,1))
N1 <- NN$new(4,c(1,50,50,50,50,1))
N1$calculate(c(1,1))
N1 <- NN$new(4,c(2,50,50,50,50,1))
N1$calculate(c(1,1))
N1 <- NN$new(4,c(2,50,50,50,50,1))
N1$calculate(c(1,1))
N1 <- NN$new(4,c(1,50,50,50,50,1))
N1$calculate(c(1,1))
NN <- R6Class("NN", list(
L = 1, #Anzahl der Layer
B = c(1), #Breite der einzelnen Layer
W = c(1,1), #Liste soll Länge der dim haben und Einträge sind Matrizen W
d = c(1), #List der Affinen Vektoren
J = 0,
theta = c(1,1),
f = sigmoid,
initialize = function(L = 1, B = c(1,1,1), W = c(1,1,1),d=c(1,1,0), min_gewicht=-2, max_gewicht = 2 ) {
stopifnot(length(B) == L+2)
self$W <- vector(mode="list",length=L+1)
self$L <- L
self$B <- B
#Erstellen der Matrizen W
for (i in (0:L)){
self$W[i+1] <- list(matrix(runif(B[i+1]*B[i+2],min=min_gewicht,max=max_gewicht),nrow=B[i+1],ncol=B[i+2]))
}
names(self$W) <- LETTERS[1:(L+1)]
#Erstellen der affinen Vektoren d
for (i in (0:(L-1))){
self$d[i+1] <- list(matrix(runif(B[i+2],min=min_gewicht,max=max_gewicht),nrow=1,ncol=B[i+2]))
}
self$d[L+1] <- 0
names(self$d) <- LETTERS[1:(L+1)]
#Erstellen des J -> braucht man hier aber wahrscheinlich nicht sondern erst in der Berechnung
for (i in (0:L)){
self$J <- self$J + norm(self$W[[i+1]],"F")
}
#Erstellen der theta
},
#calculate führt die funktion des NN aus
calculate = function(x=1){
for (j in (1:length(x))){
h <- x[j]
if (self$L >= 1){
for (i in LETTERS[1:(self$L)]){
h <- self$f(self$d[[i]] + h %*% self$W[[i]]) #letzter Schritt ist ohne Aktivierungsfunktion
}
}
h <- self$d[[LETTERS[(self$L+1)]]] + h %*% self$W[[LETTERS[(self$L+1)]]]
x[j] <- h
}
return(x)
},
calculate2 = function(x=1){
h <- x[j]
if (self$L >= 1){
for (i in LETTERS[1:(self$L)]){
h <- self$f(self$d[[i]] + h %*% self$W[[i]]) #letzter Schritt ist ohne Aktivierungsfunktion
}
}
h <- self$d[[LETTERS[(self$L+1)]]] + h %*% self$W[[LETTERS[(self$L+1)]]]
x[j] <- h
return(x)
},
eval_till_layer = function(x=1,Layer=1){
if (Layer == self$L +1){
x <- self$calculate(x)
}
if (self$L >= 1){
for (i in LETTERS[1:(Layer)]){
x <- self$f(self$d[[i]] + x %*% self$W[[i]]) #letzter Schritt ist ohne Aktivierungsfunktion
}
}
return(x)
},
#Durchführen eines Gradientdescends
GD = function(x,y,lambda=1,stepsize=1e-4,iterations=100){
n <- length(x)
R1 <- 1/n * sum((y-self$calculate(x))^2)
for (i in 1:iterations){
self$W[["A"]] <- self$W[["A"]] + 1e-3 * x[i] * (y[i]-self$calculate(x[i]))
}
R2 <- 1/n * sum((y-self$calculate(x))^2)
},
GD2 = function(x,y,lambda=1,stepsize=1e-4,iterations=100){
n <- length(x)
for (i in 1:n){
self$W[[LETTERS[self$L+1]]] <- self$W[[LETTERS[self$L+1]]] + t(0.1*self$eval_till_layer(x[i],self$L)*(y[i]-self$calculate(x[i])))
self$W[[LETTERS[self$L]]] <- self$W[[LETTERS[self$L]]] + 0.1*t(self$W[[LETTERS[self$L+1]]])*self$eval_till_layer(x[i],self$L)*(y[i]-self$calculate(x[i]))
}
},
GD3 = function(x,y,iteration=10,delta=0.02){
for (j in 1:iteration){
W_tmp <- vector(mode="list",length=self$L+1)
names(W_tmp) <- LETTERS[1:(self$L+1)]
d_tmp <- vector(mode="list",length=self$L+1)
names(d_tmp) <- LETTERS[1:(self$L+1)]
R1 <- sum((y-self$calculate(x))^2)
for (k in 1:(self$L +1)){
W_tmp[[LETTERS[k]]] <- self$W[[LETTERS[k]]]
for (l in 1:length(self$W[[LETTERS[k]]])){
self$W[[LETTERS[k]]][l] <- self$W[[LETTERS[k]]][l] + runif(1,min=-delta,max=delta)
}
d_tmp[[LETTERS[k]]] <- self$d[[LETTERS[k]]]
for (l in 1:length(self$d[[LETTERS[k]]])){
self$d[[LETTERS[k]]][l] <- self$d[[LETTERS[k]]][l] + runif(1,min=-delta,max=delta)
}
}
R2 <- sum((y-self$calculate(x))^2)
if (R1 < R2){
self$W <- W_tmp
self$d <- d_tmp
}
print(R1)
print(R2)
if (j %% 10){
print(j/10)
}
}
}
)
)
N1 <- NN$new(4,c(1,50,50,50,50,1))
N1$calculate(c(1,1))
N1$calculate2(c(1,1))
NN <- R6Class("NN", list(
L = 1, #Anzahl der Layer
B = c(1), #Breite der einzelnen Layer
W = c(1,1), #Liste soll Länge der dim haben und Einträge sind Matrizen W
d = c(1), #List der Affinen Vektoren
J = 0,
theta = c(1,1),
f = sigmoid,
initialize = function(L = 1, B = c(1,1,1), W = c(1,1,1),d=c(1,1,0), min_gewicht=-2, max_gewicht = 2 ) {
stopifnot(length(B) == L+2)
self$W <- vector(mode="list",length=L+1)
self$L <- L
self$B <- B
#Erstellen der Matrizen W
for (i in (0:L)){
self$W[i+1] <- list(matrix(runif(B[i+1]*B[i+2],min=min_gewicht,max=max_gewicht),nrow=B[i+1],ncol=B[i+2]))
}
names(self$W) <- LETTERS[1:(L+1)]
#Erstellen der affinen Vektoren d
for (i in (0:(L-1))){
self$d[i+1] <- list(matrix(runif(B[i+2],min=min_gewicht,max=max_gewicht),nrow=1,ncol=B[i+2]))
}
self$d[L+1] <- 0
names(self$d) <- LETTERS[1:(L+1)]
#Erstellen des J -> braucht man hier aber wahrscheinlich nicht sondern erst in der Berechnung
for (i in (0:L)){
self$J <- self$J + norm(self$W[[i+1]],"F")
}
#Erstellen der theta
},
#calculate führt die funktion des NN aus
calculate = function(x=1){
for (j in (1:length(x))){
h <- x[j]
if (self$L >= 1){
for (i in LETTERS[1:(self$L)]){
h <- self$f(self$d[[i]] + h %*% self$W[[i]]) #letzter Schritt ist ohne Aktivierungsfunktion
}
}
h <- self$d[[LETTERS[(self$L+1)]]] + h %*% self$W[[LETTERS[(self$L+1)]]]
x[j] <- h
}
return(x)
},
calculate2 = function(x=1){
for (j in self$B[1]) {
h <- x[j]
if (self$L >= 1){
for (i in LETTERS[1:(self$L)]){
h <- self$f(self$d[[i]] + h %*% self$W[[i]]) #letzter Schritt ist ohne Aktivierungsfunktion
}
}
h <- self$d[[LETTERS[(self$L+1)]]] + h %*% self$W[[LETTERS[(self$L+1)]]]
x[j] <- h
}
return(x)
},
eval_till_layer = function(x=1,Layer=1){
if (Layer == self$L +1){
x <- self$calculate(x)
}
if (self$L >= 1){
for (i in LETTERS[1:(Layer)]){
x <- self$f(self$d[[i]] + x %*% self$W[[i]]) #letzter Schritt ist ohne Aktivierungsfunktion
}
}
return(x)
},
#Durchführen eines Gradientdescends
GD = function(x,y,lambda=1,stepsize=1e-4,iterations=100){
n <- length(x)
R1 <- 1/n * sum((y-self$calculate(x))^2)
for (i in 1:iterations){
self$W[["A"]] <- self$W[["A"]] + 1e-3 * x[i] * (y[i]-self$calculate(x[i]))
}
R2 <- 1/n * sum((y-self$calculate(x))^2)
},
GD2 = function(x,y,lambda=1,stepsize=1e-4,iterations=100){
n <- length(x)
for (i in 1:n){
self$W[[LETTERS[self$L+1]]] <- self$W[[LETTERS[self$L+1]]] + t(0.1*self$eval_till_layer(x[i],self$L)*(y[i]-self$calculate(x[i])))
self$W[[LETTERS[self$L]]] <- self$W[[LETTERS[self$L]]] + 0.1*t(self$W[[LETTERS[self$L+1]]])*self$eval_till_layer(x[i],self$L)*(y[i]-self$calculate(x[i]))
}
},
GD3 = function(x,y,iteration=10,delta=0.02){
for (j in 1:iteration){
W_tmp <- vector(mode="list",length=self$L+1)
names(W_tmp) <- LETTERS[1:(self$L+1)]
d_tmp <- vector(mode="list",length=self$L+1)
names(d_tmp) <- LETTERS[1:(self$L+1)]
R1 <- sum((y-self$calculate(x))^2)
for (k in 1:(self$L +1)){
W_tmp[[LETTERS[k]]] <- self$W[[LETTERS[k]]]
for (l in 1:length(self$W[[LETTERS[k]]])){
self$W[[LETTERS[k]]][l] <- self$W[[LETTERS[k]]][l] + runif(1,min=-delta,max=delta)
}
d_tmp[[LETTERS[k]]] <- self$d[[LETTERS[k]]]
for (l in 1:length(self$d[[LETTERS[k]]])){
self$d[[LETTERS[k]]][l] <- self$d[[LETTERS[k]]][l] + runif(1,min=-delta,max=delta)
}
}
R2 <- sum((y-self$calculate(x))^2)
if (R1 < R2){
self$W <- W_tmp
self$d <- d_tmp
}
print(R1)
print(R2)
if (j %% 10){
print(j/10)
}
}
}
)
)
N1 <- NN$new(4,c(1,50,50,50,50,1))
N1$calculate2(c(1,1))
N1 <- NN$new(4,c(2,50,50,50,50,1))
N1$calculate2(c(1,1))
